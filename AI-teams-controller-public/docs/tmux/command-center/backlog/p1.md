## P1 - High Priority (Next 1-2 Sprints)

### Epic: Codebase Refactoring (Tech Debt)
**Status:** TODO (Boss Request 2026-01-19)
**Size:** L (Large - systematic refactoring)
**Priority:** P1 (Software stability achieved, time for tech debt)
**Assigned:** TL (lead refactor planning)

**Problem:**
Software is stable now, but tech debt has accumulated. Need systematic refactoring to improve code quality, maintainability, and reduce future bugs.

**As a** development team
**I want** to refactor the codebase systematically
**So that** code quality improves and future development is easier

**TL (Tech Lead) - MANDATORY BEFORE STARTING:**
1. **Review docs/generated-docs/** - Read complete system architecture documentation before planning refactor
2. **Follow TDD practices** - Write/update tests BEFORE refactoring (Boss emphasized this carefully)
3. **Incremental approach** - Refactor progressively, not all at once
4. **Test coverage** - Ensure existing tests pass after each refactor step

**Acceptance Criteria:**
- [ ] TL reviewed docs/generated-docs/ (system architecture)
- [ ] Refactor plan created with TDD approach
- [ ] All existing tests pass after refactor
- [ ] Code coverage maintained or improved
- [ ] No functional regressions

**Priority:** P1

**Boss Quote:**
"Overall the software is pretty stable now, but it's time to tackle those tech debt issues."

---

### Backend Health Check Performance Optimization
**Status:** TODO (Created 2026-01-13 from P0 acceptance)
**Size:** S (Small - performance investigation + fix)
**Priority:** P1 (Non-critical but affects UX)
**Assigned:** Unassigned

**Problem:**
Backend `/health` endpoint responds in 4+ seconds (both localhost and public). This causes slow initial page loads and poor UX. Target response time: <2 seconds.

**As a** developer/user
**I want** health check to respond in <2 seconds
**So that** page loads are fast and API appears responsive

**Current Metrics (2026-01-13):**
- Localhost: 4.0s response time
- Public (via tunnel): 4.1s response time
- Expected: <2s (industry standard for health checks)

**Investigation Needed:**
1. Profile `/health` endpoint - which component check is slow?
   - FastAPI: instant
   - Celery: ?
   - Redis: ?
   - PubSub: ?
2. Identify bottleneck (likely blocking I/O or network call)
3. Optimize slow component (async check, timeout, or remove from health endpoint)

**Acceptance Criteria:**
- [ ] `/health` endpoint responds in <2 seconds (both localhost and public)
- [ ] All critical components still checked
- [ ] No breaking changes to health endpoint contract
- [ ] Existing tests pass

**Priority:** P1

---

### Persistent QA Blackbox Test Scripts (Reusable Testing)
**Status:** TODO (Boss Request 2026-01-11)
**Size:** S (Small - research + design)
**Priority:** P1 (Improve QA efficiency)
**Assigned:** TL (research)

**Problem:**
QA rewrites blackbox test scripts every sprint - extremely wasteful. Basic test scenarios (UI interaction, endpoint validation, user flows) are rewritten from scratch each time instead of being saved and reused like unit tests.

**Boss Quote:**
"Every time QA does blackbox testing, they rewrite the test and it seems like they don't save it anywhere. I feel like that's really wasteful. I want it to be almost like unit tests, where every time we do major refactoring or something, we can rerun those scripts without rewriting them."

**Task for TL:**
Research and design a solution for persisting QA blackbox test scripts so they can be reused across sprints. Basic scenarios should be reusable without rewriting.

**Deliverables:**
- [ ] Research QA test persistence frameworks/tools (Playwright, Cypress, Selenium, etc.)
- [ ] Recommend approach for saving and organizing test scripts
- [ ] Design test script structure (where to save, how to organize by feature/component)
- [ ] Propose test maintenance strategy (how to handle outdated tests)
- [ ] Present recommendation to Boss for approval

**Acceptance Criteria:**
- [ ] TL research complete with framework recommendation
- [ ] Clear plan for organizing and persisting test scripts
- [ ] Strategy for reusing tests across sprints
- [ ] Boss approves recommended approach

**Note:** Boss acknowledges tests may get outdated - solve reusability first, handle maintenance later.

---

### React Native Mobile App - Automation & Testing Framework
**Status:** TODO (Boss Request 2026-01-12, Research from Jarvis)
**Size:** L (Large - mobile app development + automation)
**Priority:** P1 (Apply to Command Center before Momo Lite)
**Research:** docs/research/2026-01-12-momo-lite-FINAL-WITH-OTA.md

**Problem:**
Command Center currently web-only. Need mobile app (iOS/Android) with full automation for QA testing. Research from Momo Lite project shows viable automation frameworks.

**Boss Directive:**
Apply React Native automation research to Command Center first, then Momo Lite.

**Key Findings from Research:**

**1. Build & Deploy Automation (Bare React Native):**
- CLI automation: `npx react-native run-android` / `run-ios`
- Auto-deploys to USB-connected devices
- No manual QR scanning or Expo Go required
- Full CI/CD compatible

**2. Automated Testing Frameworks:**

**Maestro (Recommended):**
- YAML-based test flows (cross-platform iOS/Android)
- Command: `maestro test flows/`
- Zero flakiness, automatic waiting for UI elements
- Fast iteration (interpreted tests, no compilation)
- Example:
  ```yaml
  appId: com.aiteams.controller
  ---
  - launchApp
  - tapOn: "Login"
  - inputText: "username"
  - assertVisible: "Dashboard"
  ```

**Detox (Alternative):**
- Gray-box testing, React Native-specific
- Commands: `detox build` → `detox test`
- Access to app internals for reliable async handling
- Deeper integration but more setup

**3. CI/CD Integration:**
- GitHub Actions with Android/iOS emulators
- Full automation pipeline: build → install → test → report
- Structured JSON output for AI tools parsing
- No manual intervention required

**4. Over-the-Air (OTA) Updates:**
- Expo Updates for JavaScript-only changes
- Command: `eas update --channel production`
- No app store resubmission for bug fixes
- Proven safe (10+ years Apple compliance)
- Free tier: 1K MAUs

**Application to Command Center:**

**Phase 1: React Native App (Core Features)**
- [ ] Bare React Native project setup (no Expo managed workflow)
- [ ] Team selection UI
- [ ] Role pane views (PO, SM, TL, FE, BE, QA)
- [ ] Voice feedback integration
- [ ] Terminal output display

**Phase 2: Automation Framework**
- [ ] Maestro test flows setup
- [ ] Core user flow tests (login, team select, voice command)
- [ ] CI/CD pipeline (GitHub Actions)
- [ ] USB device testing workflow

**Phase 3: OTA Updates**
- [ ] Expo Updates integration
- [ ] Production/staging channels
- [ ] Automated update deployment

**Automation Commands:**
```bash
# Development
npx react-native run-android  # Deploy to USB device

# Testing with Maestro
maestro test flows/command-center.yaml

# OTA deployment
eas update --channel production --message "Bug fixes"
```

**Acceptance Criteria:**
- [ ] React Native app runs on iOS and Android
- [ ] Full CLI automation (build, deploy, test)
- [ ] Maestro test flows for core features
- [ ] CI/CD pipeline automated
- [ ] OTA updates working
- [ ] QA can run automated tests via CLI
- [ ] Boss can deploy updates without app store

**Technical Stack:**
- React Native (bare workflow, not Expo managed)
- Maestro for E2E testing
- Expo Updates for OTA
- GitHub Actions for CI/CD
- USB device deployment

**Priority:** P1 (Boss specified - apply to Command Center first)

**Next Step:** TL to create technical design after Sprint 6 (SOLID refactoring) completes.

---

### Technical Debt Evaluation (Pre-Refactor)
**Status:** TODO (Boss Request 2026-01-08)
**Size:** S (Small - research + analysis)
**Priority:** P1 (Must do BEFORE refactor)

**Problem:**
Features keep getting pushed continuously. No time to pay down technical debt. Need to evaluate current debt level before attempting refactor.

**Boss Quote:**
"We're an AI agent team, but features keep getting pushed in continuously, so there's no time to pay down technical debt. I've postponed this task for quite a while, but I feel like it's time to pay off the debt."

**Task for TL:**
Find a framework to evaluate current technical debt. Assess whether project has low, medium, or high technical debt.

**Deliverables:**
- [ ] Research technical debt evaluation frameworks
- [ ] Evaluate codebase using chosen framework
- [ ] Report: Technical debt level (low/medium/high)
- [ ] Identify top debt areas (code smells, duplication, complexity)
- [ ] Recommendations for refactor priorities

**Output:** Document in `docs/tech-debt-evaluation.md`

---

### Codebase Refactor (Pay Down Technical Debt)
**Status:** TODO (Boss Request 2026-01-08)
**Size:** L (Large - depends on debt evaluation)
**Priority:** P1 (After tech debt evaluation)

**Problem:**
Technical debt has accumulated. Features pushed continuously without refactor time. Need to pay down debt, but must be careful - breaking things is disastrous.

**Boss Requirements:**
1. **Evaluate debt FIRST** - complete "Technical Debt Evaluation" task above
2. **Write unit tests BEFORE refactoring** - must have safety net
3. **Careful execution** - if something breaks, it's disastrous
4. **Progressive refactor** - one area at a time, not everything at once

**Prerequisites:**
- [ ] Technical debt evaluation complete
- [ ] Unit test coverage adequate
- [ ] Boss approval of refactor plan

**Approach:**
1. Evaluate debt (separate task above)
2. Write/improve unit tests for target areas
3. Refactor incrementally (one module at a time)
4. Verify tests still pass after each change
5. QA testing after each refactor sprint

**Acceptance Criteria:**
- [ ] Code complexity reduced
- [ ] Test coverage increased
- [ ] No breaking changes
- [ ] Easier to maintain

---

### Pluggable TTS Architecture - SOLID Provider System
**Status:** TODO (New - Boss Request 2026-01-05)
**Size:** M (Medium - architectural refactoring)
**Priority:** P1 (Enable multiple TTS providers)

**Problem:** Current TTS implementation is tightly coupled to Google Cloud TTS. Cannot easily switch to alternative providers (HD-TTS API, OpenAI, or future providers) without modifying core code.

**As a** system administrator
**I want** a pluggable TTS provider architecture
**So that** I can switch between TTS providers (Google Cloud TTS, HD-TTS, OpenAI, or any future API) without code changes

**Current State:**
- Existing: Google Cloud TTS (Story 36 - switchable with OpenAI via env var)
- Provider switching: Via `TTS_PROVIDER` environment variable
- Location: `backend/app/services/tts_providers.py`

**New Requirement:**
- Add HD-TTS API as third provider option
- Design follows SOLID principles (Open/Closed Principle - open for extension, closed for modification)
- "Plug-in and use any TTS" architecture

**Acceptance Criteria:**
- [ ] Abstract TTS provider interface maintained (existing `TTSProvider` base class)
- [ ] HD-TTS provider implementation created (`HDTTSProvider` class)
- [ ] Supports all HD-TTS API parameters (gender, area, emotion, group, speed, quality)
- [ ] Switch providers via `TTS_PROVIDER=hdtts` environment variable
- [ ] No changes to Celery task code (`celery_tasks.py`) - provider factory handles selection
- [ ] HD-TTS API documentation available at `docs/tech/hd-tts-apis.md`
- [ ] Authentication via X-API-Key header (configurable via env var)
- [ ] Error handling for HD-TTS API failures
- [ ] All existing Google Cloud TTS and OpenAI TTS functionality preserved

**Provider Options After Implementation:**
1. `TTS_PROVIDER=google` - Google Cloud TTS (default, $4/million chars)
2. `TTS_PROVIDER=openai` - OpenAI TTS ($15/million chars)
3. `TTS_PROVIDER=hdtts` - HD-TTS API (Vietnamese-specialized)

**Technical Reference:**
- API Documentation: `docs/tech/hd-tts-apis.md`
- Current Implementation: `backend/app/services/tts_providers.py` (Story 36 architecture)
- HD-TTS Base URL: `https://hd-tts-backend.hungson175.com`
- HD-TTS Test Key: `vvtts_7e1647c466a68a36cfa401a08e1ec4a2`

**Priority:** P1

---

### Voice Speed UI Setting (Dynamic, No Server Restart)
**Status:** TODO (New - Boss Request 2026-01-05)
**Size:** S (Small - UI settings enhancement)
**Priority:** P1 (UX improvement - eliminate server restarts)

**Problem:**
Current voice speed is hardcoded in backend/.env (HDTTS_SPEED=0.58). Changing speed requires:
1. Edit backend/.env
2. Restart Celery worker
This is frustrating for users who want to adjust speed dynamically.

**As a** user
**I want** voice speed as a UI setting in the Settings panel
**So that** I can adjust speech speed dynamically without server restarts

**Current Implementation:**
- Speed hardcoded: `HDTTS_SPEED=0.58` in backend/.env
- Speed passed to TTS provider on each request
- Celery loads speed at startup

**Desired Implementation:**
- Frontend Settings panel (left side, like noise filter)
- Speed slider: range 0.5 - 2.0 (or HD-TTS API supported range)
- Speed saved to localStorage
- Speed sent with each voice feedback request to backend
- Backend uses speed from request body (not .env)
- Fallback to .env default if not specified in request

**Acceptance Criteria:**
- [ ] Add speed slider to Settings panel (0.5 - 2.0 range)
- [ ] Save speed to localStorage (e.g., `voice_feedback_speed`)
- [ ] Send speed with voice feedback API requests
- [ ] Backend reads speed from request body, not just .env
- [ ] Celery uses request speed, fallback to .env default
- [ ] No server restart required when changing speed
- [ ] Speed changes take effect immediately on next voice feedback

**Technical Notes:**
- Frontend: `components/voice/VoiceSettingsPanel.tsx`
- Backend: `app/services/celery_tasks.py` - read speed from task params
- Backend: `app/api/voice_routes.py` - pass speed from request to Celery
- Fallback: Keep `HDTTS_SPEED` in .env as default

**Priority:** P1

---

### Intelligent File Path Resolution in Terminal Quick View
**Status:** TODO (New - Boss Request 2026-01-04)
**Size:** M (Medium - looks small but complicated)
**Priority:** P1 (High - Sprint 13 feature incomplete without this)

**Problem:**
Terminal quick view popup currently fails to resolve file paths correctly. Claude Code outputs mixed path formats (relative, absolute, relative to subdirectories), causing parser to fail. Users click file paths that don't open or open wrong files.

**As a** developer viewing terminal output
**I want** file paths to resolve correctly regardless of format
**So that** clicking any file path opens the correct file

**Acceptance Criteria:**
- [ ] Resolve relative paths (./src/file.ts)
- [ ] Resolve absolute paths (/full/path/file.ts)
- [ ] Resolve paths relative to subdirectories (subdir/file.ts)
- [ ] Handle ambiguous paths (multiple matches → show user choice popup)
- [ ] Cache resolved paths (in-memory KV: project+path → file list)

**Boss Technical Guidance for TL:**
- Use search algorithm (similar to Cmd+P file search approach)
- Simple in-memory cache: key = project name + path, value = list of matches
- Multiple matches: Show popup for user to choose
- Search scope: Project files, initialize at project load, update if file not found
- "This feature looks small, but complicated" - THINK HARD from several perspectives
- BE/FE: TDD very carefully

**Priority:** P1

---

### Fix Cmd+P File Search in File Browser
**Status:** TODO (ESCALATED - Boss frustrated 2026-01-08)
**Size:** S (Small - existing feature broken)
**Priority:** P0 (CRITICAL - Boss: "works like shit, never finds files")

**Problem:**
Cmd+P search in File Browser is completely broken and unusable. Boss reports it NEVER finds the files he needs.

**Boss Quote:** "the search feature (Cmd +P) inside File Browser DOES NOT WORK! it works like shit, never found a file that I need"

**As a** developer browsing project files
**I want** Cmd+P quick search to actually find files
**So that** I can quickly find and open files without manual browsing

**Root Cause Analysis Needed:**
- [ ] Does popup open when Cmd+P pressed?
- [ ] Does search execute but return no results?
- [ ] Is uFuzzy algorithm too strict?
- [ ] Is file list cache broken/empty?
- [ ] Are results ranked poorly (right file exists but not shown)?

**Acceptance Criteria:**
- [ ] Cmd+P triggers file search popup
- [ ] Search FINDS files Boss searches for (test with real examples)
- [ ] Results ranked by relevance (fuzzy matching works)
- [ ] Selecting file opens it in editor
- [ ] Search is performant (no lag on typing)
- [ ] Boss can actually use it to find files

**Priority:** P0 (ESCALATED - Boss pain point)

**Next Step:** TL/FE diagnose why search fails, fix algorithm or caching issue

---

### Multi-User Deployment via Docker Containers
**Status:** TODO (New - Boss Request 2026-01-04)
**Size:** L (Large - deployment infrastructure + multi-tenancy)
**Priority:** P1 (High - platform scalability for limited rollout)

**Problem Statement:**
Command Center platform currently runs on Boss's local machine (single-user). Platform serves multiple use cases beyond just coding:
- **Scrum Team:** Software development (current command-center team)
- **Market Research Team:** Simulating McKinsey consulting workflows
- **Future Teams:** AI agent teams for various domains

**Current Limitation:**
- Boss's machine hosts ALL teams and workflows
- Cannot share platform with other users (2-3 max initially)
- Each new user would mess up Boss's local setup
- No isolation between users

**Boss Directive (2026-01-04):**
> "The command center is a large platform for doing all sorts of things, not just this project. Right now it's running on my machine, but for each user, I'd need to run it in a separate Docker container to avoid messing up my setup. Make it deployable in separate Docker instances."

**User Story:**
As the platform owner,
I want to deploy isolated instances for 2-3 users,
So that each user has their own environment without interfering with others or my local setup.

---

## Scope: Multi-Tenant Docker Deployment

### Target Users (Initial Rollout):
- **User 1:** Boss (current setup, becomes containerized)
- **User 2-3:** Limited beta users (invited testers)
- **Future:** Scale to more users after validating architecture

### Isolation Requirements:

**Per-User Isolation:**
- Separate tmux sessions (user1's teams ≠ user2's teams)
- Separate file systems (project files isolated)
- Separate databases (when PostgreSQL added - Sprint 25)
- Separate voice feedback (user1 audio ≠ user2 audio)
- Separate API tokens (authentication per user)

**Shared Resources:**
- Single codebase (same application code)
- Shared Redis (with user-namespaced keys)
- Shared Celery workers (with user-aware task routing)

---

## Architecture Options

### Option A: Docker Compose Multi-Container (RECOMMENDED)

**Structure:**
```yaml
services:
  # User 1 Instance
  user1-frontend:
    image: ai-teams-frontend:latest
    environment:
      - USER_ID=user1
      - BACKEND_URL=http://user1-backend:17061

  user1-backend:
    image: ai-teams-backend:latest
    environment:
      - USER_ID=user1
      - REDIS_KEY_PREFIX=user1
    volumes:
      - user1-projects:/app/projects

  # User 2 Instance
  user2-frontend:
    image: ai-teams-frontend:latest
    environment:
      - USER_ID=user2
      - BACKEND_URL=http://user2-backend:17061

  user2-backend:
    image: ai-teams-backend:latest
    environment:
      - USER_ID=user2
      - REDIS_KEY_PREFIX=user2
    volumes:
      - user2-projects:/app/projects

  # Shared Services
  redis:
    image: redis:7-alpine

  celery-worker:
    image: ai-teams-backend:latest
    command: celery worker
```

**Advantages:**
- ✅ Simple to deploy (docker-compose up)
- ✅ Easy to add new users (add service to docker-compose.yml)
- ✅ Isolation via separate containers
- ✅ Resource limits per user (Docker memory/CPU limits)

**Disadvantages:**
- ⚠️ All users on same host (Boss's machine)
- ⚠️ Manual scaling (edit YAML for new users)

---

### Option B: Kubernetes Multi-Namespace (OVER-ENGINEERED)

**Not recommended for 2-3 users** - Kubernetes overkill for initial rollout.

**When to revisit:** If users > 10, need auto-scaling, or multi-host deployment.

---

### Option C: Docker Swarm (ALTERNATIVE)

**Middle ground between Compose and Kubernetes:**
- Service replication
- Load balancing
- Multi-host support

**When to consider:** If users grow to 5-10 and need distributed deployment.

---

## Implementation Plan

### Phase 1: Dockerization (Base Infrastructure)

**Deliverables:**
- [ ] Dockerfile for frontend (Next.js production build)
- [ ] Dockerfile for backend (FastAPI + Celery)
- [ ] docker-compose.yml for single-user setup
- [ ] Environment variable configuration (USER_ID, ports, volumes)
- [ ] Volume mounts for persistent data (projects, databases)
- [ ] Health checks (frontend, backend, Redis, Celery)

**Acceptance Criteria:**
- [ ] Boss can run `docker-compose up` and system works identically to local setup
- [ ] All features work in Docker (voice, file browser, terminal, teams)
- [ ] Data persists across container restarts (volumes work)
- [ ] No performance degradation vs local setup

---

### Phase 2: Multi-User Support (Isolation)

**Deliverables:**
- [ ] User namespace isolation (Redis keys prefixed with USER_ID)
- [ ] User-specific tmux sessions (user1:command-center ≠ user2:command-center)
- [ ] User-specific file storage (separate volumes per user)
- [ ] User authentication (JWT tokens mapped to USER_ID)
- [ ] User-specific Celery task routing (tasks tagged with USER_ID)
- [ ] User-specific voice feedback (WebSocket rooms per user)

**Acceptance Criteria:**
- [ ] User 1 cannot see User 2's teams, files, or tasks
- [ ] User 1 voice feedback doesn't play to User 2
- [ ] User 1 can create teams without affecting User 2
- [ ] Concurrent usage: Both users can work simultaneously
- [ ] Zero cross-user contamination (strict isolation)

---

### Phase 3: Deployment & Access (Cloudflare Tunnels)

**Current Setup:**
- `voice-ui.hungson175.com` → localhost:3334 (Boss only)
- `voice-backend.hungson175.com` → localhost:17061 (Boss only)

**Multi-User Setup:**
- `user1.ai-teams.hungson175.com` → user1-frontend:3334
- `user2.ai-teams.hungson175.com` → user2-frontend:3334
- `user3.ai-teams.hungson175.com` → user3-frontend:3334

**Deliverables:**
- [ ] Cloudflare Tunnel configuration (multiple subdomains)
- [ ] Subdomain routing (user1.* → user1 container, user2.* → user2 container)
- [ ] SSL certificates (Cloudflare handles this)
- [ ] User onboarding documentation (how to access your instance)

**Acceptance Criteria:**
- [ ] Each user has unique subdomain URL
- [ ] Users can access their instance from anywhere (internet access)
- [ ] HTTPS working for all subdomains
- [ ] No cross-user URL access (user1 can't access user2's subdomain)

---

### Phase 4: Resource Management & Monitoring

**Deliverables:**
- [ ] Docker resource limits (CPU, memory per user container)
- [ ] Monitoring dashboard (Prometheus + Grafana)
  - Container CPU/memory usage per user
  - API request rates per user
  - Voice feedback latency per user
- [ ] Log aggregation (centralized logs for all users)
- [ ] Alerting (notify Boss if user container crashes)

**Acceptance Criteria:**
- [ ] User containers respect resource limits (no one user hogs CPU)
- [ ] Boss can view usage metrics per user
- [ ] Logs searchable by USER_ID
- [ ] Alerts sent to Boss on critical failures

---

## Technical Challenges & Solutions

### Challenge 1: Tmux in Docker
**Problem:** Tmux expects TTY, Docker containers are non-interactive.

**Solution:**
- Run tmux in detached mode (`tmux new-session -d`)
- Backend API controls tmux via `tmux send-keys` (already implemented)
- No interactive tmux access needed (web UI is the interface)

---

### Challenge 2: File System Permissions
**Problem:** Docker containers run as specific user (UID/GID), file permissions may break.

**Solution:**
- Use named volumes (Docker manages permissions)
- Set container user to match host UID (if mounting host directories)
- Use `chown` in Dockerfile entrypoint if needed

---

### Challenge 3: Redis Key Collision
**Problem:** User 1 and User 2 both create team "command-center", Redis keys collide.

**Solution:**
- Prefix all Redis keys with USER_ID: `user1:command-center:*` vs `user2:command-center:*`
- Update Redis client configuration (backend/app/services/redis_client.py)
- Ensure all Redis operations use prefixed keys

---

### Challenge 4: Celery Task Routing
**Problem:** User 1's TTS task might be executed with User 2's context.

**Solution:**
- Tag Celery tasks with USER_ID: `task.apply_async(kwargs={'user_id': 'user1'})`
- Celery worker checks USER_ID before execution
- User-specific task queues: `celery_user1_queue`, `celery_user2_queue`

---

### Challenge 5: Voice Feedback Isolation
**Problem:** User 1's voice feedback might play to User 2 if WebSocket rooms not isolated.

**Solution:**
- WebSocket room names include USER_ID: `voice-feedback-user1`, `voice-feedback-user2`
- Frontend connects to user-specific room (determined by auth token)
- Backend publishes to user-specific room only

---

## Estimated Effort

**Phase 1 (Dockerization):** 1-2 weeks
- Create Dockerfiles
- Configure docker-compose.yml
- Test single-user Docker deployment
- Fix Docker-specific issues (tmux, permissions, etc.)

**Phase 2 (Multi-User Support):** 2-3 weeks
- Implement USER_ID isolation layer
- Refactor Redis, Celery, WebSocket for user namespaces
- Test concurrent multi-user scenarios
- Fix isolation bugs

**Phase 3 (Deployment):** 1 week
- Configure Cloudflare Tunnels
- Set up subdomain routing
- User onboarding + documentation

**Phase 4 (Monitoring):** 1 week
- Set up Prometheus + Grafana
- Configure alerts
- Create dashboards

**Total: 5-7 weeks** for full multi-user Docker deployment

---

## Success Criteria

**Functional:**
- [ ] 2-3 users can access their own isolated instances
- [ ] Zero cross-user contamination (strict isolation verified)
- [ ] All features work in Docker (voice, file browser, terminal, teams)
- [ ] Performance equivalent to local setup (no degradation)

**Deployment:**
- [ ] `docker-compose up` deploys all user instances
- [ ] New user onboarding: < 10 minutes (add config, restart)
- [ ] Data persists across restarts (volumes work correctly)

**Boss Validation:**
- [ ] Boss comfortable inviting 2-3 beta users
- [ ] Boss can monitor resource usage per user
- [ ] Boss's local setup unaffected (runs in Docker too)

---

## Dependencies

**Blockers:**
- None - can start immediately

**Nice to Have (Not Blockers):**
- PostgreSQL migration (Sprint 25) - would simplify multi-user data isolation
- Refactoring Epic (P0) - cleaner architecture makes Dockerization easier

**Enables:**
- Beta user testing (real user feedback on platform)
- Revenue potential (SaaS model if successful)
- Scalability testing (identify bottlenecks with real users)

---

## Future Enhancements (Post-Launch)

**After 2-3 users validated:**
- User self-registration (currently invite-only)
- Usage-based pricing ($X/month per user)
- User management dashboard (Boss can add/remove users via UI)
- Auto-scaling (spin up containers on demand)
- Multi-host deployment (if users > 10, spread across machines)

---

**Created By:** PO (Product Owner)
**Date:** 2026-01-04
**Status:** TODO - Awaiting prioritization vs Mini IDE Epic and Refactoring Epic
**Priority:** P1 (High - enables platform scalability)

---

### Vietnamese Educational Content Library (Audio + Textbooks)
**Status:** TODO (New - Boss Request 2026-01-03)
**Size:** L (Large - content platform with multiple features)
**Priority:** P1 (High - educational platform for Vietnamese students)

**Problem:** Vietnamese students need a centralized platform to access educational content (textbooks, audio materials) for all subjects and grades (1-12).

**User Story:**
As a Vietnamese student,
I want to access textbooks and audio materials for all subjects and grades,
So that I can review lessons and study efficiently without managing multiple resources.

**Target Audience:**
- Vietnamese students (grades 1-12)
- Focus: Review and self-study

**Content Requirements:**

1. **Subjects (All Grades 1-12):**
   - Geography (Địa lý)
   - History (Lịch sử)
   - Math (Toán)
   - Vietnamese Literature (Ngữ văn)
   - Physics (Vật lý)
   - Chemistry (Hóa học)
   - Biology (Sinh học)
   - English
   - All other curriculum subjects

2. **Audio Constraint:**
   - Total audio content: Under 10GB
   - Format: Compressed audio (MP3 or similar)
   - Quality: Optimized for voice clarity

3. **Content Organization:**
   - By Subject → Grade → Chapter
   - Example: History → Grade 8 → Chapter 3

**UI/UX Requirements:**

1. **Default Selection:**
   - Auto-detect/set current grade level
   - Or allow manual grade selection on first launch
   - Remember user's grade preference

2. **Subject Selection:**
   - Option 1: Select specific subject + grade (e.g., "History Grade 8")
   - Option 2: Select all subjects (default)
   - Show available subjects as grid or list

3. **Chapter Selection:**
   - After selecting subject + grade, show chapter list
   - Allow multi-select or single chapter selection
   - Visual progress indicator (completed/in-progress chapters)

4. **Content Upload/Selection:**
   - Allow manual content upload (admin/teacher feature)
   - OR select from pre-loaded content library
   - Validate file formats (PDF for textbooks, MP3/audio for recordings)

**Acceptance Criteria:**

- [ ] Subject library loaded for all Vietnamese curriculum subjects (grades 1-12)
- [ ] User can select grade level (default: current grade or configurable)
- [ ] User can filter by subject (Geography, History, Math, etc.)
- [ ] User can view chapters within selected subject + grade
- [ ] Chapter selection interface (multi-select or individual)
- [ ] Default behavior: Show all subjects, allow filtering
- [ ] Audio content available (under 10GB total)
- [ ] Content organization: Subject → Grade → Chapter hierarchy
- [ ] Search functionality (search by subject, chapter name, keyword)
- [ ] Progress tracking (which chapters user has studied)
- [ ] Responsive UI (works on mobile, tablet, desktop)

**Technical Considerations:**

1. **Content Storage:**
   - Database schema: Subjects → Grades → Chapters → Resources (PDF, audio)
   - File storage: S3/CDN for textbooks and audio files
   - Metadata: Subject name, grade, chapter number, title, description

2. **Audio Optimization:**
   - Use compressed audio formats (MP3 at 64-128 kbps for voice)
   - Lazy loading (download on-demand, not all at once)
   - Audio player with playback speed control (0.5x, 1x, 1.5x, 2x)

3. **Content Management:**
   - Admin interface to upload/manage content
   - Versioning (handle textbook updates across school years)
   - Content validation (file type, size, metadata completeness)

4. **User Experience:**
   - Fast content browsing (virtualized lists for large chapter counts)
   - Offline support (progressive web app, cache downloaded content)
   - Bookmark/favorite chapters

5. **Performance:**
   - Index by subject + grade for fast filtering
   - Pagination for chapter lists (if hundreds of chapters)
   - CDN for static content delivery

**Proposed Breakdown:**

1. **Phase 1:** Database schema + basic subject/grade/chapter structure
2. **Phase 2:** Content upload interface (admin tool)
3. **Phase 3:** Student UI - subject/grade selection
4. **Phase 4:** Chapter list + audio player integration
5. **Phase 5:** Search, progress tracking, bookmarks
6. **Phase 6:** Offline support (PWA)

**Files to Create/Modify:**
- Database schema: `subjects`, `grades`, `chapters`, `resources` tables
- Backend API: Subject/grade/chapter endpoints
- Frontend: Education library UI component
- Admin interface: Content management dashboard

**Dependencies:**
- Audio player library (e.g., Howler.js, React Player)
- File upload/storage (S3 or local filesystem)
- PDF viewer component (if showing textbooks in-app)

**Notes:**
- This is a separate educational platform feature (different domain from AI Teams Controller)
- High impact for Vietnamese student audience
- Requires significant content curation and upload effort
- Consider partnership with Vietnamese education publishers for content licensing

---


